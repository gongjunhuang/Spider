**当当网爬虫实战**

lesson.py

    import scrapy
    from ts.items import TsItem
    from scrapy.http import Request
    
    class LessonSpider(scrapy.Spider):
        name = 'lesson'
        allowed_domains = ['hellobi.com']
        start_urls = ['https://edu.hellobi.com/course/242']
    
        def parse(self, response):
            item = TsItem()
            item['title'] = response.xpath("//ol[@class='breadcrumb']/li[@class='active']/text()").extract()
            item['link'] = response.xpath("//ul[@class='nav nav-tabs']/li[@class='active']/a/@href").extract()
            item['student'] = response.xpath("//span[@class='course-view']/text()").extract()
            yield item
    
            for i in range(1, 247):
                url = 'https://edu.hellobi.com/course/' + str(i)
                yield Request(url, callback=self.parse)


pipelines.py

    class TsPipeline(object):
    
        def __init__(self):
            self.fh = open('E:/171229model/tianshan/lesson.txt', 'w')
    
        def process_item(self, item, spider):
            print(item['title'])
            print(item['link'])
            print(item['student'])
            print('----------------')
            self.fh.write(item['title'][0]+'\n'+item['link'][0]+'\n'+item['student'][0]+'\n'+'----------------\n')
            return item
    
        def close_spider(self):
            self.fh.close()

    class TsItem(scrapy.Item):
        # define the fields for your item here like:
        # name = scrapy.Field()
        title = scrapy.Field()
        link = scrapy.Field()
        student = scrapy.Field()