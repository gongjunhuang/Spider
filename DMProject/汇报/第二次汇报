第八课： Noise and Error

1. Noise and Probablistic target

Data Sets的Noise一般有三种情况：

--由于人为因素，正类被误分为负类，或者负类被误分为正类；

--同样特征的样本被模型分为不同的类；

--样本的特征被错误记录和使用。

之前的数据集是确定的，即没有Noise的，叫做Deterministic。现在有Noise了，也就是说在某点处不再是确定分布，而是概率分布了，即对每个(x，y)出现的概率是P(y|x)。

因为Noise的存在，比如在x点，有0.7的概率y=1，有0.3的概率y=0，即y是按照P(y|x)分布的。数学上可以证明如果数据集按照P(y|x)概率分布且是iid的，那么以前证明机器可以学习的方法依然奏效，VC Dimension有限即可推断Ein和Eout是近似的。

P(y|x) 称之为目标分布（Target Distribution）。它实际上告诉我们最好的选择是什么，同时伴随着多少noise。其实，没有noise的数据仍然可以看成“特殊”的P(y|x)概率分布，即概率仅是1和0.对于以前确定的数据集： 
        P(y|x)=1,for y=f(x)

        P(y|x)=0,for y≠f(x)


2. ERROR Measure
机器学习需要考虑的问题是找出的矩g与目标函数f有多相近，之前一直使用Eout进行误差的估计，那一般的错误测量有哪些形式呢？

矩g对错误的衡量有三个特性：

--out-of-sample：样本外的未知数据

--pointwise：对每个数据点x进行测试

--classification：看prediction与target是否一致，classification error通常称为0/1 error

PointWise error实际上就是对数据集的每个点计算错误并计算平均，pointwise error一般可以分成两类：0/1 error和squared error。0/1 error通常用在分类（classification）问题上，而squared error通常用在回归（regression）问题上。


Ideal Mini-Target由P(y|x)和err共同决定，0/1 error和squared error的Ideal Mini-Target计算方法不一样。0/1 error中的mini-target是取P(y|x)最大的那个类，而squared error中的mini-target是取所有类的加权平方和。

有了错误衡量，就会知道当前的矩g是好还是不好，并会让演算法不断修正，得到更好的矩g，从而使得g与目标函数更接近。



3. Algorithmic Error Measure
Error有两种：false accept和false reject。false accept意思是误把负类当成正类，false reject是误把正类当成负类。 根据不同的机器学习问题，false accept和false reject应该有不同的权重，这根实际情况是符合的，比如是超市优惠，那么false reject应该设的大一些；如果是安保系统，那么false accept应该设的大一些。



4. Weighted Classification
实际上，机器学习的Cost Function即来自于这些error，也就是算法里面的迭代的目标函数，通过优化使得Error（Ein）不断变小。 
cost function中，false accept和false reject赋予不同的权重，在演算法中体现。对不同权重的错误惩罚，可以选用virtual copying的方法。