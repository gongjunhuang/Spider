决策树：从根节点一步一步走到叶子节点

根节点-----非叶子节点-----叶子节点

每个节点相当于在数据中切分一次，所以并不是节点越多越好

训练与测试：

训练阶段：从给定的训练集中构造出来一棵树，从根节点开始选择特征，如何进行特征切分

测试阶段：根据构造出来的树模型从上到下走一遍

一旦构造好了决策树，那么分类或者预测任务很简单了，主要问题在于构造一棵树

如何切分特征：

通过一种衡量标准，来计算通过不同特征进行分支选择后的分类情况，找出来最好的那个当根节点

熵：随机变量不确定性的度量

信息增益：表示特征X使得类Y的不确定性减少的程度。

CART：使用GINI系数当作衡量标准      1 - p^2

剪枝策略：决策树过拟合风险很大，理论上可以完全分得开数据

策略：预剪枝（边建立决策树边剪枝），使用较多  。限制深度，叶子节点个数，叶子节点样本数，信息增益量等

后剪枝（当建立完决策树后来进行剪枝），通过一定标准衡量
