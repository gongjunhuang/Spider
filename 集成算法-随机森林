Ensemble Learning

目的：让机器学习效果更好，单个不行的话，用多个

bagging：训练多个分类器取平均

bootstrap aggregation（并行训练一堆分类器），最典型代表随机森林

    随机：数据采样随机，特征选择随机
    森林：很多个决策树并行放在一起

    优势：

    能够处理高维度的数据，并且不用做特征选择；训练结束之后，能够给出哪些feature比较重要；
    容易做成并行化方法，速度比较快；可以进行可视化展示，便于分析

boosting：让弱学习器开始加强，通过加权来进行训练

    Adaboost：根据前一次分类效果调整数据权重，如果某一个数据在这次分错了，下一次会给它更大的权重

        最终结果：每个分类器根据自身的准确性来确定各自的权重

stacking：聚合多个分类或者回归模型

堆叠：很暴力，拿来一堆直接上


D:\baiduyun\pydata-book-2nd-edition\datasets\titanic\train.csv

Titanic
