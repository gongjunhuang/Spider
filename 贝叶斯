贝叶斯

优点：
对待预测样本进行预测，过程简单速度快(想想邮件分类的问题，预测就是分词后进行概率乘积，在log域直接做加法更快)。
对于多分类问题也同样很有效，复杂度也不会有大程度上升。
在分布独立这个假设成立的情况下，贝叶斯分类器效果奇好，会略胜于逻辑回归，同时我们需要的样本量也更少一点。
对于类别类的输入特征变量，效果非常好。对于数值型变量特征，我们是默认它符合正态分布的。

缺点：
对于测试集中的一个类别变量特征，如果在训练集里没见过，直接算的话概率就是0了，预测功能就失效了。当然，我们前面的文章提过我们有一种技术叫做**『平滑』操作**，可以缓解这个问题，最常见的平滑技术是拉普拉斯估测。
那个…咳咳，朴素贝叶斯算出的概率结果，比较大小还凑合，实际物理含义…恩，别太当真。
朴素贝叶斯有分布独立的假设前提，而现实生活中这些predictor很难是完全独立的。

最常见应用场景

文本分类/垃圾文本过滤/情感判别：这大概会朴素贝叶斯应用做多的地方了，即使在现在这种分类器层出不穷的年代，
在文本分类场景中，朴素贝叶斯依旧坚挺地占据着一席之地。原因嘛，大家知道的，因为多分类很简单，同时在文本数据中，
分布独立这个假设基本是成立的。而垃圾文本过滤(比如垃圾邮件识别)和情感分析(微博上的褒贬情绪)用朴素贝叶斯也通常能取得很好的效果。

多分类实时预测：这个是不是不能叫做场景？对于文本相关的多分类实时预测，它因为上面提到的优点，被广泛应用，简单又高效。

推荐系统：是的，你没听错，是用在推荐系统里！！朴素贝叶斯和协同过滤(Collaborative Filtering)是一对好搭档，协同过滤是强相关性，但是泛化能力略弱，朴素贝叶斯和协同过滤一起，能增强推荐的覆盖度和效果。

正向概率：假设袋子里面有N个白球，M个黑球，取黑球的概率多大

逆向概率：事先不知道袋子里黑白球的比例，直接摸一个或者多个球，观察取出来之后球的颜色，
可以就此堆袋子里面黑白球的比例作出什么样的推测

编辑距离：
两个词之间的编辑距离定义为使用了几次插入、删除、交换、替换的操作把一个词变成另一个词

```
import re, collections

def words(text):
    return re.findall('[a-z]+', text.lower())

def train(feature):
    model = collections.defaultdict(lambda: 1)
    for f in feature:
        model[f] += 1
    return model

NWORDS = train(words(open('big.txt').read()))
alphabet = 'abcdefghijklmnopqrstuvwxyz'

def edits1(words):
    n = len(word)
    return set([word[0:i] + word[i+1:] for i in range(n)] +                             #deletion
              [word[0:i] + word[i+1:] + word[i] + word[i+2:] for i in range(n-1)] +     #transposition
              [word[0:i] + c + word[i+1:] for i in range(n) for c in alphabet] +        #alteration
              [word[0:i] + c + word[i:] for i in range(n) for c in alphabet])           #insertion

def edits2(words):
    return set(e2 for e1 in edits1(words) for e2 in edits1(e1))

def known(words):
    return set(w for w in words if w in NWORDS)

def correct(word):
    candidates = known([word]) or known(edits1(word)) or known(edits2(word)) or [word]
    return max(candidates, key=lambda w: NWORDS[w])

```

建模：

高斯分布型：用于classification问题，假定属性/特征是服从正态分布的。

多项式型：用于离散值模型里。比如文本分类问题里面我们提到过，我们不光看词语是否在文本中出现，也得看出现的次数。如果总词数为n，出现词数为m的话，说起来有点像掷骰子n次出现m次这个词的场景。

伯努利型：这种情况下，就如之前博文里提到的bag of words处理方式一样，最后得到的特征只有0(没出现)和1（出现过）































1.1 规定动作

SQL查询：JOIN ON、DISTINCT、GROUP BY、ORDER BY等等。从数据库中提取数据是数据分析的第一步。另外如果数据规模是TB级的，所以还要能使用SQL让集群做一些简单的计算，不然都下载到本地的话运算资源是肯定不够的。可能还会问一些非常基础的问题，比如PRIMARY KEY、int、str、double之类。

Excel：数据透视表、VLOOKUP、COUNTIFS、SUMIFS、VAR.P、条件格式等等，可能会涉及到诸如VLOOKUP中的TRUE和FALSE参数有什么区别，VAR.P和VAR.S有什么区别等细节问题。

1.2 自选动作

根据简历来问，简历上写什么就问什么，会问得比较深入。Python、Stata、R、SPSS、SAS、EViews都算比较常见的数据分析工具。顺便奉劝各位要一定要真实。比如简历上写“精通Python”，虽然面试官知道简历注水是常态，但既然都“精通”了，那如果面试官问到pandas，regular expression，DataFrame.iterrows()返回的是Series还是dictionary还是listof tuples，tuple和list的区别的时候好歹都得答出来吧……


2.逻辑思维

主要分为两方面，对业务逻辑的理解能力和行文的逻辑水平。

2.1 业务逻辑

虽然一个业务看似流程简单清晰，但产生数据的复杂程度往往超过大多数人的想象。对业务逻辑的考察主要通过相关项目经历。如果是典型的学校项目，面试官会比较关心指标设计选取、代理变量选择、误差分析、因果性解释等。

这里再次提醒大家，写在简历上的项目经历起码自己要非常熟悉，对答如流。如果面试官听你介绍15秒项目后提出的问题(如“你为什么说 北京经济适用房建筑面积与房屋建造年份的乘积 是一个非常重要且有实际意义的解释变量？”)就能把你难住的话，那你也会把面试官难住的——面试评价表怎么写啊摔！面试官回去就得把HR批判一番！！！


2.2 行文逻辑

毕竟最终产出是一份份报告，可能是HTML邮件也能是PDF。文章结构还是很重要的。不过最关键的几点是先说结论，先写摘要。

3.理论储备

也分为规定动作和可选动作。

3.1 规定动作

主要是基础的统计学理论，如方差、协方差、算数平均数、几何平均数、中位数、众数、分位值、双峰数据、长尾数据、假设检验、期望迭代法则、贝叶斯原理等。


3.2 自选动作

根据简历来问，简历上写什么面试官一定会问什么。第三次奉劝各位写的检验也好机器学习算法也好好歹自己要知道原理、适用条件、局限性。不然面试官跟你聊起Pearson distance、K-means cluster的随机性问题的时候你接不上来也是很尴尬的。


4.对细节的敏感度

作为数据分析师，每天要关注大量数据指标。对细节的敏感度是非常必要的。这主要分为两方面，对统计口径的敏感度和对数据的敏感度。

4.1 统计口径

统计口径一致是确保数据可比性的基础，这非常考验数据分析师的敏感度和行业经验。比如转化率，是点击算转化还是注册算转化还是购买算转化？配送时间，是从用户下单开始计时还是从订单确认开始计时还是从商品出库开始计时？客单价包不包括配送费、打包费、代金券形式的折扣优惠？


4.2 数据

面试官非常关心候选人对数据异常波动、离群值、平均数没有代表意义等情况的迅速识别能力。比如已知然寿司套餐单价1,500，酒水单价300，平均客单价2,500，能不能马上想到这可能是双峰数据或者长尾数据，抑或既双峰又长尾的数据？


5.学习能力

互联网行业瞬息万变，光数据的存储就有Oracle、MySQL、Hadoop、Spark、Hive、Impala、谷哥哥三驾马车等一大堆奇奇怪怪的东西。互联网行业的从业者经常要面对新需求、新工具、新方法。能否迅速掌握新知识，解决新问题是候选人必须证明给面试官看的。

主要考察的方式是了解过往项目经历，或者由面试官出作业题(比如Sci-Hub)。

6.排版和简单UI设计

面试官认为数据分析报告必须简洁、清晰、重点突出。主要考察方式是出作业题让候选人限时交一份slides(就是PPT啦)出来。能掌握标准的Microsoft Design Language是大大的加分项。

7.价值观

主要看工作热情、态度、道德水平等等，这方面面试官问的问题比较随机，没什么规律可循，甚至问过机械键盘、人体工程学设计等方面的问题。


1.不同公司内部对数据分析团队的定位不同，所以对于数据分析师的技能要求也会有差别。

比方说，需不需要熟练使用SQL，需不需要掌握数据挖掘算法，在不同岗位之间的差别很大。建议应聘者在找工作之前好好研究下意向公司的JD，做到有的放矢，还是那句老话“知己知彼、百战不殆”。（此处可参考part1部分提供的招聘岗位要求）


2.如果面试被拒也不要气馁，有可能并不是你的原因，只是与岗位要求不匹配。

业务方向的数据分析师岗位很看重对于特定业务的理解能力，不同业务条线的分析内容也会有差别，这对于工作经验较少的应届生来说是很薄弱的一环。另外，公司一般只会在特定方向有人力缺口的情况下招人，有可能会导致招聘的岗位与你的条件不匹配，而与你条件匹配的岗位不招人。


3.如果不能直接获得数据分析师的offer，也可以通过产品、运营等岗位曲线救国。

互联网公司的产品、运营工作中有很多需要和数据打交道的地方，每次功能改进、版本迭代、活动上线都需要自己做一部分数据分析。因为数据分析对于业务理解的要求比较高，对于已经熟悉公司业务的产品、运营同学来说，内部转岗到数据分析部门的优势比较大。据了解数据分析师有一半是从其他岗位转过来的。

4.数据分析师工作的结果是支持企业管理决策，数据分析报告是分析师提供的结果依据。

数据工具学习是日积月累的学习过程，比较而言数据分析报告有极强的规律性，明白其间的逻辑思路，对于数据分析师结果呈现的锦上添花立竿见影。
