**json数据的处理**

    import json
    data = json.loads(data)
    data.keys()
    data.values()
    data['id']
    
京东爬虫

crawl爬虫：

整站链接爬下来，根据rules进行过滤，执行业务代码


商品Id

16278915632

商品价格

[https://p.3.cn/prices/mgets?callback=jQuery1946753&type=1&area=1&pdtk=&pduid=1072980774&pdpin=&pin=null&pdbp=0&skuIds=J_16278915632&ext=11000000&source=item-pc]

评论

(https://sclub.jd.com/comment/productPageComments.action?callback=fetchJSON_comment98vv5039&productId=16278915632&score=0&sortType=5&page=1&pageSize=10&isShadowSku=0&rid=0&fold=1)


    from scrapy.linkextractors import LinkExtractor
    from scrapy.spiders import CrawlSpider, Rule
    import re
    from urllib.request import urlopen
    
    from douban.items import DoubanItem
    
    
    class JdSpider(CrawlSpider):
        name = 'JD'
        allowed_domains = ['jd.com']
        start_urls = ['http://jd.com/']
    
        rules = (
            Rule(LinkExtractor(allow=''), callback='parse_item', follow=True),
        )
    
        def parse_item(self, response):
    
            #i['domain_id'] = response.xpath('//input[@id="sid"]/@value').extract()
            #i['name'] = response.xpath('//div[@id="name"]').extract()
            #i['description'] = response.xpath('//div[@id="description"]').extract()
            try:
                item = DoubanItem()
                thisurl = response.url
                pattern = "item.jd.com/(.*?).html"
                x = re.search(pattern, thisurl)
                if(x):
                    thisId = re.compile(pattern).findall(thisurl)[0]
                    print(thisId)
                    title = response.xpath("//html/head/title/text()").extract()
                    shop = response.xpath("div[@class='name']/a[@target='_blank']/text()").extract()
                    shop_link = response.xpath("div[@class='name']/a[@target='_blank']/@href").extract()
                    priceurl = 'https://p.3.cn/prices/mgets?callback=jQuery1946753&type=1&area=1&pdtk=&pduid=1072980774&pdpin=&pin=null&pdbp=0&skuIds=J_'+str(thisId)+'&ext=11000000&source=item-pc'
                    commenturl = 'https://sclub.jd.com/comment/productPageComments.action?callback=fetchJSON_comment98vv5039&productId='+ str(thisId)+'&score=0&sortType=5&page=0&pageSize=10&isShadowSku=0&rid=0&fold=1'
    
                    priceData = urlopen(priceurl).read().decode('utf-8', 'ignore')
                    commentData = urlopen(commenturl).read().decode('utf-8', 'ignore')
                    pricePat = '"p":"(.*?)"'
                    commentPat = '"goodRateShow":(.*?),'
                    price = re.compile(pricePat).findall(priceData)
                    comment = re.compile(commentPat).findall(commentData)
    
                    if (len(title) and len(shop) and len(shop_link) and len(price) and len(comment)):
                        print(title[0])
                        print(shop[0])
                        print(shop_link[0])
                        print(price[0])
                        print(comment[0])
                        print('=========')
                    else:
                        pass
                else:
                    pass
            except Exception as e:
                print(e)
                
**    重新设置mysql密码**
    
 1、 首先检查mysql服务是否启动，若已启动则先将其停止服务，可在开始菜单的运行，使用命令：
net stop mysql 
打开第一个cmd1窗口，切换到mysql的bin目录，运行命令：
mysqld --defaults-file="C:\Program Files\MySQL\MySQL Server 5.1\my.ini" --console --skip-grant-tables

注释：
该命令通过跳过权限安全检查，开启mysql服务，这样连接mysql时，可以不用输入用户密码。  此时已经开启了mysql服务了！

这个窗口保留 不关闭。

2、打开第二个cmd2窗口，连接mysql：

输入命令：
mysql -u root -p

出现：
Enter password:

在这里直接回车，不用输入密码。
然后就就会出现登录成功的信息， 

使用命令：
show databases;

使用命令切换到mysql数据库：
use mysql;

使用命令更改root密码：
UPDATE user SET Password=PASSWORD('newpassword') where USER='root';

刷新权限：
FLUSH PRIVILEGES;

然后退出，重新登录： 
quit

重新登录： 可以关掉之前的cmd1 窗口了。然后用net start mysql 启动服务
mysql -u root -p

出现输入密码提示，输入新的密码即可登录：
Enter password: ***********

显示登录信息： 成功  就一切ok了