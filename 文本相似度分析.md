TF-IDF，余弦相似度，向量空间模型

归根结底还是词语相似度的计算，如果某个词或短语在一篇文章中出现的频率高，并且在其他文章中很少出现，则认为此词或者短语具有很好的类别区分能力，适合用来分类。

TF_IDF是一种统计方法的，TF是词频term frequency，IDF逆向文件频率inverse document frequency，它的大小与一个词的常见程度成反比。

TF = 某个词在文章中出现的次数/文章中总词数

IDF = log(语料库中文档总数/(包含该词的文档数+1))

知道了"词频"（TF）和"逆文档频率"（IDF）以后，将这两个值相乘，就得到了一个词的TF-IDF值。某个词对文章的重要性越高，它的TF-IDF值就越大。

TF-IDF算法的优点是简单快速，结果比较符合实际情况。缺点是，单纯以"词频"衡量一个词的重要性，不够全面，有时重要的词可能出现次数并不多。而且，这种算法无法体现词的位置信息，出现位置靠前的词与出现位置靠后的词，都被视为重要性相同，这是不正确的。（一种解决方法是，对全文的第一段和每一段的第一句话，给予较大的权重。）

（1）使用TF-IDF算法，找出两篇文章的关键词；

（2）每篇文章各取出若干个关键词（比如20个），合并成一个集合，计算每篇文章对于这个集合中的词的词频（为了避免文章长度的差异，可以使用相对词频）；

（3）生成两篇文章各自的词频向量；

（4）计算两个向量的余弦相似度，值越大就表示越相似。

应用这种算法进行文本相似度分析，在python中封装在gensim中
doc2bow

稀疏向量：密集向量的值就是一个普通的Double数组 而稀疏向量由两个并列的 数组indices和values组成 例如：向量(1.0,0.0,1.0,3.0)用密集格式表示为[1.0,0.0,1.0,3.0]，用稀疏格式表示为(4,[0,2,3],[1.0,1.0,3.0]) 第一个4表示向量的长度(元素个数)，[0,2,3]就是indices数组，[1.0,1.0,3.0]是values数组 表示向量0的位置的值是1.0，2的位置的值是1.0,而3的位置的值是3.0,其他的位置都是0

稀疏矩阵：

相似度计算的步骤：

1、读取文档

2、对要计算的多篇文档进行分词

3、对文档进行整理成指定格式，方便后续进行计算

4、计算出词语的频率

5、【可选】对频率低的词语进行过滤

6、通过语料库建立词典

7、加载要对比的文档

8、将要对比的文档通过doc2bow转化为稀疏向量

9、对稀疏向量进行进一步处理，得到新语料库

10、将新语料库通过tfidfmodel进行处理，得到tfidf

11、通过token2id得到特征数

12、稀疏矩阵相似度，从而建立索引

13、得到最终相似度结果

gensim库：gensim是一个主题模型的python库，它可以将文本转换为向量，抽取文本中的关键词，比较文本间的相似程度。gensim好用的地方是可以实现word2vec，输入的是文本，输出的是向量。

gensim主要三个模块：

corpora:将文本转为向量，这里的向量是很简单的模型向量，只是为文档建立词典，然后计算文档中每个词出现的次数

models:将corpora得到的简单的模型向量转换为其他不同的向量，包括tfidf，lsi，lda等。

similarities：计算文本相似度的方法

```
from gensim import corpora, models, similarities
import jieba
from collections import defaultdict

frequency = defaultdict(int)
dictionary = corpora.Dictionary(text)
dictionary.save()

doc = "path"
data = open(doc).read()
data1 = jieba.cut(data)
list = ""
for item in data1:
    list += item + " "
new_data = list
#通过gensim 转化为tf-idf 形式
#把所有文本转化为词包
new_vec = dictionary.doc2bow(new_data.split(" "))
corpus = [dictionary.doc2bow(text) for text in texts]
#使用tf-idf 模型得出该评论集的tf-idf 模型
tfidf = models.TfidfModel(corpus)
#特性个数
featureNum = len(dictionary.token2id.keys())
##把所有文本做成索引
index = similarities.SparseMatrixSimilarity(tfidf[corpus], num_features=featureNum)
#此处已经计算得出所有评论的tf-idf 值
sim = index[tfidf[new_vec]]
```


遇到问题：

1.jieba在pip install之后在jupyter上没有效果

在anaconda终端上，anaconda search -t conda jieba查找对应版本，然后使用conda install -c jiangxiluning jieba=0.36.2这种方式安装
